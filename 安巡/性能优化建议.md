# 安巡系统性能优化建议

## 当前性能问题分析

### 1. 模型对话响应慢
**问题原因：**
- 使用qwen3:8b大模型，推理时间较长
- 每次请求都包含完整对话历史，增加处理时间
- 60秒超时设置过长，用户体验差
- 缺少流式响应，用户无法看到实时输出

### 2. 缺少思考过程标签
**问题原因：**
- 系统提示词未要求模型使用<think></think>标签
- 模型输出格式未规范化

### 3. 页面切换加载慢
**问题原因：**
- Streamlit状态管理效率低
- 缓存机制不够完善
- 重复的API调用和状态检查

## 优化方案

### 1. 模型对话性能优化

#### 1.1 启用流式响应
```python
# 修改后端API支持流式响应
@app.route('/api/chat_stream', methods=['POST'])
def chat_with_ai_stream():
    def generate():
        # 流式调用Ollama API
        payload = {
            "model": "qwen3:8b",
            "messages": messages,
            "stream": True
        }
        
        response = requests.post(url, json=payload, stream=True)
        for line in response.iter_lines():
            if line:
                yield f"data: {line.decode('utf-8')}\n\n"
    
    return Response(generate(), mimetype='text/plain')
```

#### 1.2 优化对话历史管理
```python
class ChatMemory:
    def __init__(self, max_history=5):  # 减少历史记录数量
        self.max_history = max_history
        self.sessions = {}
    
    def get_context(self, session_id, include_system_prompt=True):
        session = self.get_session(session_id)
        messages = []
        
        if include_system_prompt:
            messages.append({
                "role": "system",
                "content": "你是安巡智能体。请在回答时使用<think>思考过程</think>标签展示你的分析过程，然后给出简洁的回答。"
            })
        
        # 只保留最近的对话
        recent_messages = session[-self.max_history*2:] if len(session) > self.max_history*2 else session
        for msg in recent_messages:
            messages.append({"role": msg["role"], "content": msg["content"]})
        
        return messages
```

#### 1.3 模型选择优化
```python
# 考虑使用更小的模型或本地优化
MODEL_CONFIG = {
    "fast": "qwen2.5:3b",      # 快速响应模式
    "balanced": "qwen3:8b",   # 平衡模式
    "accurate": "qwen3:14b"   # 高精度模式
}

def get_optimal_model(message_length, complexity):
    if message_length < 100 and complexity == "low":
        return MODEL_CONFIG["fast"]
    elif complexity == "high":
        return MODEL_CONFIG["accurate"]
    else:
        return MODEL_CONFIG["balanced"]
```

### 2. 前端性能优化

#### 2.1 改进缓存策略
```python
# 分层缓存，减少不必要的API调用
@st.cache_data(ttl=300)  # 5分钟缓存
def get_system_status():
    return check_backend_status(), check_ollama_status()

@st.cache_data(ttl=60)   # 1分钟缓存
def get_chat_history(session_id):
    return call_backend_api(f"/api/get_chat_history?session_id={session_id}")

@st.cache_data(ttl=1800) # 30分钟缓存
def get_education_resources():
    return load_education_resources()
```

#### 2.2 异步加载和懒加载
```python
# 使用session state缓存页面数据
if 'page_data' not in st.session_state:
    st.session_state.page_data = {}

def load_page_data(page_name):
    if page_name not in st.session_state.page_data:
        with st.spinner(f"加载{page_name}数据..."):
            st.session_state.page_data[page_name] = fetch_page_data(page_name)
    return st.session_state.page_data[page_name]
```

#### 2.3 优化状态检查
```python
# 减少状态检查频率
@st.cache_data(ttl=120, show_spinner=False)
def get_cached_status():
    backend_status = False
    ollama_status = False
    
    try:
        # 并行检查状态
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            backend_future = executor.submit(check_backend_health)
            ollama_future = executor.submit(check_ollama_health)
            
            backend_status = backend_future.result(timeout=1)
            ollama_status = ollama_future.result(timeout=1)
    except:
        pass
    
    return backend_status, ollama_status
```

### 3. 数据库优化

#### 3.1 使用SQLite存储聊天历史
```python
import sqlite3
from contextlib import contextmanager

class DatabaseChatMemory:
    def __init__(self, db_path="chat_history.db"):
        self.db_path = db_path
        self.init_db()
    
    @contextmanager
    def get_db_connection(self):
        conn = sqlite3.connect(self.db_path)
        try:
            yield conn
        finally:
            conn.close()
    
    def add_message(self, session_id, role, content):
        with self.get_db_connection() as conn:
            conn.execute(
                "INSERT INTO messages (session_id, role, content, timestamp) VALUES (?, ?, ?, ?)",
                (session_id, role, content, datetime.now().isoformat())
            )
            conn.commit()
    
    def get_recent_messages(self, session_id, limit=10):
        with self.get_db_connection() as conn:
            cursor = conn.execute(
                "SELECT role, content FROM messages WHERE session_id = ? ORDER BY timestamp DESC LIMIT ?",
                (session_id, limit)
            )
            return list(reversed(cursor.fetchall()))
```

### 4. 网络优化

#### 4.1 连接池和重用
```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# 创建会话对象，重用连接
session = requests.Session()
retry_strategy = Retry(
    total=3,
    backoff_factor=1,
    status_forcelist=[429, 500, 502, 503, 504],
)
adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=10, pool_maxsize=20)
session.mount("http://", adapter)
session.mount("https://", adapter)

def call_ollama_api_optimized(payload):
    return session.post("http://localhost:11434/api/chat", json=payload, timeout=30)
```

### 5. 监控和日志

#### 5.1 性能监控
```python
import time
import functools

def performance_monitor(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        
        execution_time = end_time - start_time
        if execution_time > 2.0:  # 记录超过2秒的慢查询
            print(f"[SLOW] {func.__name__} took {execution_time:.2f}s")
        
        return result
    return wrapper

@performance_monitor
def chat_with_ai():
    # 原有逻辑
    pass
```

## 实施优先级

### 高优先级（立即实施）
1. 启用流式响应
2. 优化系统提示词，添加思考标签
3. 减少对话历史长度
4. 改进前端缓存策略

### 中优先级（1-2周内）
1. 实施数据库存储
2. 添加性能监控
3. 优化网络连接

### 低优先级（长期优化）
1. 模型量化和优化
2. 分布式部署
3. CDN加速

## 预期效果

- **对话响应时间**：从10-30秒降低到3-8秒
- **页面切换速度**：从2-5秒降低到0.5-1秒
- **系统稳定性**：减少超时和错误率
- **用户体验**：实时看到AI思考过程，更好的交互反馈

## 监控指标

- API响应时间
- 页面加载时间
- 内存使用率
- 错误率
- 用户会话时长